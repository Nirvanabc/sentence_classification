DESCRIPTION:
constants.py -- константы

corpora_good_kp -- текст рецензий (позитивные) с кинопоиска

input.txt -- 111M статей из журнала Наука и Жизнь (без цифр, а жаль. Не проследила за этим.
При желании можно перезакачать)

kp_get_data.py -- скачивает рецензии с кинопоиска

min_char_rnn.py -- программа А. Карпаты (без tensorflow, только pyton и numpy), без LSTM





RESULTS:

без LSTM (min_char_rnn):
13M nkj
 ца, этве комы корадую, что пребжа За изаислиде году, стачить выновилько кяерней стрелод нячем, не поичтычиних фручения плак понболя и инты куча мошечномься ди рух-ловочанаюго назы.
  В ренабыз. Кетор…
  ----
iter 125000, loss: 57.113956


По статье Замощина (см. TO READ(9))
lstm_size = 512
hidden_size = 100

5,9M short_input.txt

В этой научной статьено оболочистернием наспорутив несто о серенния
слесте никиритово провосние. Не прадиме слети вотат и поразовых вромо
прамерина, поликорана сли в не пели пради вель о стеренные,
празватольсо полечное перудают промунати и насльных проводов но ну
стерне и мерикой валетьния пестовальных извиленные мерание преновых
стильшим стовоми и нестриминый, что велить в косторитативит вы
овотовально о петиторни посов полев воратов потовоть остра с сом
нераннам но варет истарны о веслома итоваеще прадинию поримит сталесь
о
INFO:tensorflow:Restoring parameters from checkpoints/i386_l512.ckpt
Epoch: 2/20...  Training Step: 387...  Training loss: 2.4813...  3.0337 sec/batch


lstm_size = 700
hidden_size = 400

1-я эпоха, 1100 итерация.
INFO:tensorflow:Restoring parameters from checkpoints/i900_l700.ckpt
В этой научной статье, но выделять от петерах. Он не с начала каслите
слубую с новыми наскомом столи напарните в напериальстве самали по
тере, коночное принадельно, носящая станца. Восприителесь их приверный
верх положен проверите посключалась встретительного в настринениях
образуются в кольцентом, приводили правильной приминные, составляет
серть, что случае в стании, получил не подам и для стору на возрудели
в струхней. Однак свою при немолюте им оданно в приворх собреняющие
пологи сознать стоятил не своим, станиях соберханиях. Наказывает
собершивается в помощих паратеров из превоздаваются в тем сосудал
правой ил слиши по настоящим, когорому в нементом, что на себя стала.:
Не осладованные. Отныси в свазах соступается проитходов пати
приставаться отданиваться на создании сородников, крипительно
последаться в полостействуе имеющего случает с строином и называемые
перевы из полеков с сробоваленными собромами, состремение объедиля,
когда не облизающимс и слеваемые воды соброменный в серед полновым
облекам.
Epoch: 1/20...  Training Step: 1136...  Training loss: 1.8788...  5.7410 sec/batch



TO READ:

1. http://karpathy.github.io/2015/05/21/rnn-effectiveness/  --
статья Карпатова на английском о результатах работы, с ссылками на исходный
код (github)

2. https://colah.github.io/posts/2015-08-Understanding-LSTMs/ --
англ. статья про LSTM

3. https://moluch.ru/archive/95/21426/ -- перевод 2. (легче по нему)

5. https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=1 курс Стенфорда по CNN (раньше
преподавал А. Карпатый)

6. http://cs231n.github.io/neural-networks-case-study/
Написание softmax, cross entropy и backpropagation (eng)

7. https://cs.stanford.edu/people/karpathy/cs231nfiles/minimal_net.html рисунок результата (и весь код впридачу)

8. https://github.com/karpathy/char-rnn  код с LSTM (Torch),
полезные вещи в описании (подбор параметров в зависимости
от размера данных, ссылки на полезную инфу).

9. https://habrahabr.ru/post/342738/  tensorflow! LSTM! русский!
генерация текстов по одному символу!
